{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Fashion NMIST 2.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "yjKpaa3AbcJE",
        "guJzPQgabk3r"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shaodwing/nmist-fashion/blob/Adding-callback/Fashion_NMIST_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ycgJ9Q0OT0hF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Used Joseph Redmon on tiny darknet to produce my work\n",
        "#Used the work of Adrian Rosebrock for the learning rate schedule\n",
        "\n",
        "import datetime\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "\n",
        "from keras import backend as K\n",
        "from keras import utils\n",
        "from keras.callbacks import Callback, LearningRateScheduler, ModelCheckpoint\n",
        "from keras.datasets import fashion_mnist\n",
        "from keras.layers import Input, Dense, BatchNormalization, Conv2D, GlobalAveragePooling2D, Activation, LeakyReLU, MaxPooling2D\n",
        "from keras.models import Model\n",
        "from keras.optimizers import SGD\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.metrics import classification_report\n",
        "from clr_callback import *\n",
        "from learningratefinder import *"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZcktjWXYbqD7",
        "colab_type": "text"
      },
      "source": [
        "#Load Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wOTeN7Hzbpv8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.random.seed(2019)\n",
        "tf.set_random_seed(2019)\n",
        "\n",
        "(X_train, Y_train ), (X_test, Y_test ) = fashion_mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8IdADgEFvBnU",
        "colab_type": "text"
      },
      "source": [
        "#Tiny dark net"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2dUhDCpxu_pO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "c780fa73-5bd8-411a-9190-b7aa5d408130"
      },
      "source": [
        "batch_size = 256\n",
        "num_classes = 10 \n",
        "epochs = 100\n",
        "img_cols = X_train.shape[1]\n",
        "img_rows = X_train.shape[2]\n",
        "\n",
        "# CLR hyper-parameters\n",
        "baseLr = 1e-4 #1e-3\n",
        "maxLr = 2e-1 #2e-1\n",
        "stepSize = 8\n",
        "clrMethod = \"triangular\"\n",
        "\n",
        "# name file\n",
        "lrfind_plot_path = os.path.sep.join([\"/content/output\", \"lrfind_plot.png\"])\n",
        "training_plot_path = os.path.sep.join([\"/content/output\", \"training_plot.png\"])\n",
        "clr_plot_path = os.path.sep.join([\"/content/output\", \"clr_plot.png\"])\n",
        "\n",
        "date = datetime.datetime.now().strftime('%b %d %D %M')\n",
        "saveWeightsPath = '/content/checkpoint' + date\n",
        "\n",
        "\n",
        "if K.image_data_format() == 'channels_first':\n",
        "  X_train = X_train.reshape(X_train.shape[0], 1, img_rows, img_cols);\n",
        "  X_test  = X_test.reshape(X_test.shape[0], 1, img_rows, img_cols);\n",
        "  input_shape = (1, img_rows, img_cols);\n",
        "else: \n",
        "  X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1);\n",
        "  X_test  = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1);\n",
        "  input_shape = (img_rows, img_cols, 1);\n",
        "\n",
        "\n",
        "X_train = X_train.astype('float32')\n",
        "X_test  = X_test.astype('float32')\n",
        "X_train /= 255\n",
        "X_test  /= 255\n",
        "\n",
        "Y_train = utils.to_categorical(Y_train, num_classes)\n",
        "Y_test  = utils.to_categorical(Y_test, num_classes)\n",
        "Y_label = [\"T-shirt/top\",\"Trouser\",\"Pullover\",\"Dress\",\"Coat\",\"Sandal\",\"Shirt\",\"Sneaker\",\"Bag\",\"Ankle boot\"]\n",
        "\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28, 1)\n",
            "(10000, 28, 28, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vcqhDcGwRa5T",
        "colab_type": "text"
      },
      "source": [
        "#Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LbjuTgDpxN07",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def layerConv(output, filters, size, stride, pad, batch_normalization=True, activation='LeakyReLU'):\n",
        "  output = Conv2D(kernel_size = (size,size), filters = filters, strides=stride, padding=pad)(output)\n",
        "  if batch_normalization:\n",
        "    output = BatchNormalization()(output);\n",
        "  \n",
        "  #Activation layer\n",
        "  if activation=='LeakyReLU':\n",
        "    output = LeakyReLU(alpha = 0.1)(output)\n",
        "  else:\n",
        "    output = Activation(activation)(output)\n",
        "  \n",
        "  return output\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1YunSxL6Rdby",
        "colab_type": "text"
      },
      "source": [
        "#Tensor model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rp7tlDl2vysT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "07790796-7b22-4ffa-9495-4bce73910f85"
      },
      "source": [
        "#LAYERS\n",
        "#First set of convolution (9-12)\n",
        "input_img = Input(shape=input_shape)\n",
        "\n",
        "\"\"\" Small darknet\n",
        "output = layerConv(output=input_img, filters=32, size=3, batch_normalization=True, stride=1, pad=\"same\", activation='LeakyReLU')\n",
        "output = layerConv(output=output   , filters=8 , size=1, batch_normalization=True, stride=1, pad=\"same\", activation='LeakyReLU')\n",
        "output = layerConv(output=output   , filters=64, size=3, batch_normalization=True, stride=1, pad=\"same\", activation='LeakyReLU')\n",
        "output = layerConv(output=output   , filters=8 , size=1, batch_normalization=True, stride=1, pad=\"same\", activation='LeakyReLU')\n",
        "output = layerConv(output=output   , filters=64, size=3, batch_normalization=True, stride=1, pad=\"same\", activation='LeakyReLU')\n",
        "\n",
        "#Max pooling to get 14x14 feature (13)\n",
        "output = MaxPooling2D(pool_size=(2, 2), strides=(2,2), padding='same', data_format=None)(output)\n",
        "\n",
        "output = layerConv(output=output   , filters=16, size=1, batch_normalization=True, stride=1, pad=\"same\", activation='LeakyReLU')\n",
        "output = layerConv(output=output   , filters=64, size=3, batch_normalization=True, stride=1, pad=\"same\", activation='LeakyReLU')\n",
        "output = layerConv(output=output   , filters=16, size=1, batch_normalization=True, stride=1, pad=\"same\", activation='LeakyReLU')\n",
        "output = layerConv(output=output   , filters=64, size=3, batch_normalization=True, stride=1, pad=\"same\", activation='LeakyReLU')\n",
        "output = layerConv(output=output   , filters=16, size=1, batch_normalization=True, stride=1, pad=\"same\", activation='LeakyReLU')\n",
        "\"\"\"\n",
        "\n",
        "output = layerConv(output=input_img, filters=128, size=3, batch_normalization=True, stride=1, pad=\"same\", activation='LeakyReLU')\n",
        "output = layerConv(output=output   , filters=32 , size=1, batch_normalization=True, stride=1, pad=\"same\", activation='LeakyReLU')\n",
        "output = layerConv(output=output   , filters=256, size=3, batch_normalization=True, stride=1, pad=\"same\", activation='LeakyReLU')\n",
        "output = layerConv(output=output   , filters=32 , size=1, batch_normalization=True, stride=1, pad=\"same\", activation='LeakyReLU')\n",
        "output = layerConv(output=output   , filters=256, size=3, batch_normalization=True, stride=1, pad=\"same\", activation='LeakyReLU')\n",
        "\n",
        "#Max pooling to get 14x14 feature (13)\n",
        "output = MaxPooling2D(pool_size=(2, 2), strides=(2,2), padding='same', data_format=None)(output)\n",
        "\n",
        "#Second set of convolution (14-19)\n",
        "output = layerConv(output=output, filters=64 , size=1, batch_normalization=True, stride=1, pad=\"same\", activation='LeakyReLU')\n",
        "output = layerConv(output=output, filters=256, size=3, batch_normalization=True, stride=1, pad=\"same\", activation='LeakyReLU') #512\n",
        "output = layerConv(output=output, filters=64 , size=1, batch_normalization=True, stride=1, pad=\"same\", activation='LeakyReLU')\n",
        "output = layerConv(output=output, filters=256, size=3, batch_normalization=True, stride=1, pad=\"same\", activation='LeakyReLU') #512\n",
        "output = layerConv(output=output, filters=64 , size=1, batch_normalization=True, stride=1, pad=\"same\", activation='LeakyReLU') #128\n",
        "\n",
        "\n",
        "\n",
        "#Last layer to get an output of 10 class (19+)\n",
        "output = layerConv(output=output, filters=10, size=1, batch_normalization=False, stride=1, pad=\"same\", activation='linear')\n",
        "output = GlobalAveragePooling2D()(output)\n",
        "output = Activation('softmax')(output)\n",
        "\n",
        "model = Model(input_img, output)\n",
        "model.summary()\n",
        "\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_3 (InputLayer)         (None, 28, 28, 1)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_23 (Conv2D)           (None, 28, 28, 128)       1280      \n",
            "_________________________________________________________________\n",
            "batch_normalization_21 (Batc (None, 28, 28, 128)       512       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_21 (LeakyReLU)   (None, 28, 28, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_24 (Conv2D)           (None, 28, 28, 32)        4128      \n",
            "_________________________________________________________________\n",
            "batch_normalization_22 (Batc (None, 28, 28, 32)        128       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_22 (LeakyReLU)   (None, 28, 28, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_25 (Conv2D)           (None, 28, 28, 256)       73984     \n",
            "_________________________________________________________________\n",
            "batch_normalization_23 (Batc (None, 28, 28, 256)       1024      \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_23 (LeakyReLU)   (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_26 (Conv2D)           (None, 28, 28, 32)        8224      \n",
            "_________________________________________________________________\n",
            "batch_normalization_24 (Batc (None, 28, 28, 32)        128       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_24 (LeakyReLU)   (None, 28, 28, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_27 (Conv2D)           (None, 28, 28, 256)       73984     \n",
            "_________________________________________________________________\n",
            "batch_normalization_25 (Batc (None, 28, 28, 256)       1024      \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_25 (LeakyReLU)   (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 14, 14, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_28 (Conv2D)           (None, 14, 14, 64)        16448     \n",
            "_________________________________________________________________\n",
            "batch_normalization_26 (Batc (None, 14, 14, 64)        256       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_26 (LeakyReLU)   (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_29 (Conv2D)           (None, 14, 14, 256)       147712    \n",
            "_________________________________________________________________\n",
            "batch_normalization_27 (Batc (None, 14, 14, 256)       1024      \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_27 (LeakyReLU)   (None, 14, 14, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_30 (Conv2D)           (None, 14, 14, 64)        16448     \n",
            "_________________________________________________________________\n",
            "batch_normalization_28 (Batc (None, 14, 14, 64)        256       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_28 (LeakyReLU)   (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_31 (Conv2D)           (None, 14, 14, 256)       147712    \n",
            "_________________________________________________________________\n",
            "batch_normalization_29 (Batc (None, 14, 14, 256)       1024      \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_29 (LeakyReLU)   (None, 14, 14, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_32 (Conv2D)           (None, 14, 14, 64)        16448     \n",
            "_________________________________________________________________\n",
            "batch_normalization_30 (Batc (None, 14, 14, 64)        256       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_30 (LeakyReLU)   (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_33 (Conv2D)           (None, 14, 14, 10)        650       \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 14, 14, 10)        0         \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_3 ( (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "activation_6 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 512,650\n",
            "Trainable params: 509,834\n",
            "Non-trainable params: 2,816\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dIxs0Eog2EwR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "#Learning Rate schedule\n",
        "LearningRateSchedule = CyclicLR( mode=clrMethod,\n",
        "                                base_lr=baseLr,\n",
        "                                max_lr=maxLr,\n",
        "                                step_size= stepSize * (X_train.shape[0] // batch_size))\n",
        "callbacks = []\n",
        "callbacks.append(LearningRateSchedule)\n",
        "\n",
        "checkpointCallback = ModelCheckpoint(saveWeightsPath,\n",
        "                                     monitor='val_loss',\n",
        "                                     verbose=0,\n",
        "                                     save_best_only=True,\n",
        "                                     save_weights_only=False,\n",
        "                                     mode='auto',\n",
        "                                     period=1)\n",
        "callbacks.append(checkpointCallback)\n",
        "\n",
        "opt = SGD(lr=baseLr, momentum=0.9)\n",
        "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "aug = ImageDataGenerator(horizontal_flip=True, vertical_flip=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1DtHORso0QOp",
        "colab_type": "text"
      },
      "source": [
        "#Finding best learning rate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vBSLbvUtmaTy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 674
        },
        "outputId": "c88e9b0a-08ab-4c9c-cf52-f64e6c1aa242"
      },
      "source": [
        "findBestLR = False\n",
        "if findBestLR:\n",
        "  \n",
        "  # Search for the best learning rate\n",
        "  # initialize the learning rate finder and then train with learning\n",
        "  # rates ranging from 1e-10 to 1e+1\n",
        "  print(\"[INFO] finding learning rate...\")\n",
        "  lrf = LearningRateFinder(model)\n",
        "  lrf.find(\n",
        "    aug.flow(X_train, Y_train, batch_size=batch_size),\n",
        "    1e-10, 1e+1,\n",
        "    stepsPerEpoch=np.ceil((len(X_train) / float(batch_size))),\n",
        "    batchSize=4)#batch_size)\n",
        "\n",
        "  # plot the loss for the various learning rates and save the\n",
        "  # resulting plot to disk\n",
        "  lrf.plot_loss()\n",
        "  #plt.savefig(lrfind_plot_path)\n",
        "\n",
        "  # gracefully exit the script so we can adjust our learning rates\n",
        "  # in the config and then train the network for our full set of\n",
        "  # epochs\n",
        "  print(\"[INFO] learning rate finder complete\")\n",
        "  print(\"[INFO] examine plot and adjust learning rates before training\")"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] finding learning rate...\n",
            "Epoch 1/9\n",
            "235/235 [==============================] - 87s 370ms/step - loss: 2.4340 - acc: 0.1450\n",
            "Epoch 2/9\n",
            "235/235 [==============================] - 84s 358ms/step - loss: 2.4341 - acc: 0.1463\n",
            "Epoch 3/9\n",
            "235/235 [==============================] - 84s 358ms/step - loss: 2.4336 - acc: 0.1470\n",
            "Epoch 4/9\n",
            "235/235 [==============================] - 84s 357ms/step - loss: 2.4261 - acc: 0.1569\n",
            "Epoch 5/9\n",
            "235/235 [==============================] - 84s 357ms/step - loss: 2.3404 - acc: 0.2161\n",
            "Epoch 6/9\n",
            "235/235 [==============================] - 84s 358ms/step - loss: 1.7668 - acc: 0.4250\n",
            "Epoch 7/9\n",
            "235/235 [==============================] - 84s 358ms/step - loss: 0.8186 - acc: 0.7617\n",
            "Epoch 8/9\n",
            "235/235 [==============================] - 84s 358ms/step - loss: 0.4945 - acc: 0.8231\n",
            "Epoch 9/9\n",
            "222/235 [===========================>..] - ETA: 4s - loss: 0.8857 - acc: 0.7745[INFO] learning rate finder complete\n",
            "[INFO] examine plot and adjust learning rates before training\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEOCAYAAACaQSCZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nooQhIiJRUcIQEZGo/H9T3xOSz6MU0wAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t01fLJ8_aNIT",
        "colab_type": "text"
      },
      "source": [
        "#Training\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ArDz3c65V0jN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 859
        },
        "outputId": "e53f8b65-7420-41e2-c7a3-38c8e0f505dc"
      },
      "source": [
        "\"\"\"\n",
        "model.fit(X_train, Y_train,\n",
        "          epochs=epochs,\n",
        "          batch_size=batch_size,\n",
        "          shuffle=True, \n",
        "          validation_data=(X_test, Y_test),\n",
        "          callbacks=callbacks)\n",
        "\"\"\"\n",
        "model.fit_generator(aug.flow(X_train, Y_train,\n",
        "                            batch_size=batch_size,\n",
        "                            shuffle=True, seed=None),\n",
        "                    steps_per_epoch=len(X_train) // batch_size,\n",
        "                    epochs=epochs,\n",
        "                    validation_data=(X_test, Y_test),\n",
        "                    callbacks=callbacks)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "234/234 [==============================] - 24s 102ms/step - loss: 1.5175 - acc: 0.5187 - val_loss: 9.6263 - val_acc: 0.0972\n",
            "Epoch 2/100\n",
            "234/234 [==============================] - 23s 97ms/step - loss: 0.5697 - acc: 0.8016 - val_loss: 2.5854 - val_acc: 0.5139\n",
            "Epoch 3/100\n",
            "234/234 [==============================] - 23s 97ms/step - loss: 0.4430 - acc: 0.8439 - val_loss: 1.1857 - val_acc: 0.6344\n",
            "Epoch 4/100\n",
            "234/234 [==============================] - 23s 97ms/step - loss: 0.3974 - acc: 0.8592 - val_loss: 1.2203 - val_acc: 0.6238\n",
            "Epoch 5/100\n",
            "234/234 [==============================] - 23s 97ms/step - loss: 0.3656 - acc: 0.8710 - val_loss: 1.4777 - val_acc: 0.5524\n",
            "Epoch 6/100\n",
            "234/234 [==============================] - 23s 97ms/step - loss: 0.3478 - acc: 0.8777 - val_loss: 2.4261 - val_acc: 0.5967\n",
            "Epoch 7/100\n",
            "234/234 [==============================] - 23s 97ms/step - loss: 0.3327 - acc: 0.8821 - val_loss: 0.8515 - val_acc: 0.7536\n",
            "Epoch 8/100\n",
            "234/234 [==============================] - 23s 97ms/step - loss: 0.3160 - acc: 0.8873 - val_loss: 0.7826 - val_acc: 0.7638\n",
            "Epoch 9/100\n",
            "234/234 [==============================] - 23s 97ms/step - loss: 0.2991 - acc: 0.8942 - val_loss: 0.7337 - val_acc: 0.7579\n",
            "Epoch 10/100\n",
            "234/234 [==============================] - 23s 97ms/step - loss: 0.2828 - acc: 0.8999 - val_loss: 0.4382 - val_acc: 0.8405\n",
            "Epoch 11/100\n",
            "234/234 [==============================] - 23s 97ms/step - loss: 0.2629 - acc: 0.9066 - val_loss: 0.7277 - val_acc: 0.7568\n",
            "Epoch 12/100\n",
            "234/234 [==============================] - 23s 97ms/step - loss: 0.2515 - acc: 0.9101 - val_loss: 0.3638 - val_acc: 0.8759\n",
            "Epoch 13/100\n",
            "204/234 [=========================>....] - ETA: 2s - loss: 0.2357 - acc: 0.9163"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-e7aa94f14095>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                     callbacks=callbacks)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1656\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1657\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1658\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1659\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1660\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    213\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[1;32m    214\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m                                             class_weight=class_weight)\n\u001b[0m\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1447\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1448\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1449\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1450\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1451\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2977\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2979\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2980\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2981\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2935\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2936\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2937\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2938\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2939\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "APY2Y9yveP18",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions = model.predict(X_test, batch_size=batch_size)\n",
        "print(classification_report(y_true=Y_test.argmax(axis=1),\n",
        "                            y_pred=predictions.argmax(axis=1),\n",
        "                            target_names=Y_label))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}